---
title: "p8105_hw6_rz2570"
author: "Ruilian Zhang"
date: "11/25/2021"
output: 
  github_document:
    pandoc_args: --webtex
---

### Note: There are embeded LaTex expressions in the text of Problem 2. A dark mode of github may not be able to show the expressions while a  light mode shows them perfectly regarding to the contrast with the light background.

```{r}
library(tidyverse)
library(modelr)
library(mgcv)

theme_set(theme_minimal() + theme(legend.position = "bottom", plot.title = element_text(hjust = 0.5)))

set.seed(1)
```


## Problem 1

```{r import and clean data}
birth_df = read_csv("data/birthweight.csv") %>% 
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, "male" = "1", "female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(frace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4", "other" = "8"),
    malform = as.logical(malform),
    mrace = as.factor(mrace),
    mrace = fct_recode(mrace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4"))

 
birth_df %>% 
  summarize_all(~ sum(is.na(.))) %>% 
  knitr::kable()
```

* Convert some numeric data to factor for regression analysis.  
* The table above shows that there are no missing values in the data.  

```{r build a regression model}
plot_a = 
  birth_df %>% 
    ggplot(aes(x = blength, y = bwt)) +
    geom_point() +
    labs(
      title = "Baby's birth weight against birth length",
      x = "Birth length",
      y = "Birth weight",
      subtitle = "A"
    )

plot_a

fit = lm(bwt ~ blength, data = birth_df)

fit %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

plot_b = 
  birth_df %>% 
    modelr::add_residuals(., fit) %>% 
    modelr::add_predictions(., fit) %>% 
    ggplot(aes(x = pred, y = resid)) +
    geom_point(alpha = .3) +
    labs(
      title = "Model residuals against fitted values",
      x = "Predictions",
      y = "Residuals",
      subtitle = "B"
    )

plot_b
```

* Modeling process: 
  + After searching online, it seems that birth length has an association with birth weight, and birth length is used as the predictor of birth weight in some research.  
  + From plot A, we can find that baby's length at birth might have an linear association with baby's birth weight. So `blength` can be chosen as the predictor of the first linear model.  
  + A linear model was fitted, using `blength` as the predictor and `bwt` as the outcome.  
  + We can see from the statistic and p-value of the table above that the model is statistically significant.  
* Describe plot B: The plot shows the predicted values against the residuals of the model, in which the residuals are centered around 0 for most predictions ranging from 2000-4000. For predictions below 2000 and over 4000, there are some extreme outliers of residuals and the distribution of the residual gets skewed, which indicates this linear model might not be optimal for birth weight values under 2000 and over 4000.  

```{r fit two more models}
fit1 = lm(bwt ~ blength + gaweeks, data = birth_df)

fit1 %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)

fit2 = lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = birth_df)

fit2 %>% 
  broom::tidy() %>% 
  knitr::kable(digits = 3)
```

* The output table of `fit1` shows that the model is statistically significant for both `blength` and `gaweeks` as predictors.  
* The output table of `fit2` shows that the standard error of `babysexfemale` is large, and the p-value of the coefficient of `bhead` interacting with `blength` is not significant, which indicates they might not be good predictors of the model.

```{r compare models}
cv_df = crossv_mc(birth_df, 100) %>% 
  mutate(
    model_1 = map(train, ~lm(bwt ~ blength, data = .x)),
    model_2 = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_3 = map(train, ~lm(bwt ~ bhead + blength + babysex + bhead*blength + bhead*babysex + blength*babysex + bhead*blength*babysex, data = .x))) %>% 
  mutate(
    rmse_model_1 = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model_2 = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)),
    rmse_model_3 = map2_dbl(model_3, test, ~rmse(model = .x, data = .y))
  )

plot_c = 
  cv_df %>% 
    select(starts_with("rmse")) %>% 
    pivot_longer(
      everything(),
      names_to = "model",
      values_to = "rmse",
      names_prefix = "rmse_") %>% 
    mutate(model = fct_inorder(model)) %>% 
    ggplot(aes(x = model, y = rmse)) +
    geom_violin() +
    labs(
      title = "Distribution of root mean squared errors for each model",
      x = "Model",
      y = "Root mean squared errors",
      subtitle = "C"
    )

plot_c
```

* Plot C shows that model 1 has the largest rmse, and model 3 has much more smaller rmse than model 1 and 2. Also, the distribution of rmse in model 3 is more centered than the other two models.  
* These indicate that model 3 (using head circumference, length, sex, and all interaction as predictors) predicts baby's birth weight the best among three models.

 
## Problem 2

```{r load Central Prak data}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

```{r bootstrapping and plot for R-Squared}
weather_results_rsq = 
  weather_df %>% 
    bootstrap(n = 5000, id = "strap_number") %>%
    mutate(
      models = map(strap, ~ lm(tmax ~ tmin, data = .x)), 
      results = map(models, broom::glance)) %>% 
    select(strap_number, results) %>% 
    unnest(results)

rsq_plot = 
  weather_results_rsq %>% 
  ggplot(aes(x = r.squared)) +
  geom_density() +
  labs(
    x = "R-Squared",
    y = "Density",
    title = "Distribution of R-Squared",
    subtitle = "D"
  )

rsq_plot
```

* From plot D we can see that the distribution of $\hat{r}^2$ values is unimodal and is slightly left-skewed, and the values are centered within  0.91-0.92.  
* Thus, the plot indicates that this bootstrapping sample might be a good sample for linear regression analysis.

```{r bootstrapping and plot for beta}
weather_results_beta = 
  weather_df %>% 
    bootstrap(n = 5000, id = "strap_number") %>%
    mutate(
      models = map(strap, ~ lm(tmax ~ tmin, data = .x)), 
      results = map(models, broom::tidy)) %>% 
    select(strap_number, results) %>% 
    unnest(results) %>% 
    select(strap_number, term, estimate) %>% 
    pivot_wider(
      names_from = term,
      values_from = estimate
    ) %>% 
  rename( "intercept" = "(Intercept)") %>% 
  mutate(
    product = intercept * tmin,
    log_product = log(product)
  )

beta_plot = 
  weather_results_beta %>% 
  ggplot(aes(x = log_product)) +
  geom_density() +
  labs(
    x = "Log(beta0*beta1)",
    y = "Density",
    title = "Distribution of log(beta0*beta1)",
    subtitle = "E"
  )

beta_plot
```

* From plot E we can see that the distribution of $log(\hat{\beta_0} * \hat{\beta_1})$ values is unimodal and is symmetric in general, and the values are centered within 2.00-2.025.  

```{r confidence interval}
rsq_conf_int = 
  weather_results_rsq %>% 
    summarize(
        rsq_lower = quantile(r.squared, 0.025),
        rsq_upper = quantile(r.squared, 0.975)
      ) %>% 
  as_tibble()

rsq_conf_int %>% 
  knitr::kable(digits = 3)

beta_conf_int = 
  weather_results_beta %>% 
    summarize(
        beta_lower = quantile(log_product, 0.025),
        beta_upper = quantile(log_product, 0.975)
      ) %>% 
  as_tibble()

beta_conf_int %>% 
  knitr::kable(digits = 3)
```

* The 95% confidence interval of $\hat{r}^2$ is (`r round(rsq_conf_int[1,1], 3)`, `r round(rsq_conf_int[1,2], 3)`).  
* The 95% confidence interval of $log(\hat{\beta_0} * \hat{\beta_1})$ is (`r round(beta_conf_int[1,1], 3)`, `r  round(beta_conf_int[1,2], 3)`). 